import cv2
import mediapipe as mp
import torch
import serial
import time

# ==========================================
# 1. ä¸²å£åˆå§‹åŒ– (ä¸ ESP32 æ¡æ‰‹)
# ==========================================
try:
    # è¿™é‡Œçš„ COM9 æ˜¯ä½ åˆšæ‰çƒ§å½•æˆåŠŸçš„ç«¯å£
    # å¿…é¡»ç¡®ä¿ VS Code çš„ä¸²å£ç›‘è§†å™¨å·²å…³é—­ï¼Œå¦åˆ™ä¼šæŠ¥é”™ Access Denied
    ser = serial.Serial('COM9', 115200, timeout=1)
    print("âœ… æˆåŠŸè¿æ¥åˆ° ESP32 (COM9)")
    time.sleep(2)  # ç­‰å¾…ç¡¬ä»¶é‡å¯ç¨³å®š
except Exception as e:
    print(f"âŒ æ— æ³•è¿æ¥ä¸²å£: {e}")
    ser = None


# ==========================================
# 2. å®šä¹‰å¹¶åŠ è½½ä½ çš„ PyTorch æ¨¡å‹
# ==========================================
class TinyHandModel(torch.nn.Module):
    def __init__(self):
        super(TinyHandModel, self).__init__()
        self.fc1 = torch.nn.Linear(63, 32)
        self.fc2 = torch.nn.Linear(32, 16)
        self.fc3 = torch.nn.Linear(16, 3)  # 0:çŸ³å¤´, 1:å‰ªåˆ€, 2:å¸ƒ
        self.relu = torch.nn.ReLU()

    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        return self.fc3(x)


device = torch.device("cpu")
model = TinyHandModel().to(device)

try:
    # è½½å…¥ä½ ä¹‹å‰è®­ç»ƒå¥½çš„æƒé‡æ–‡ä»¶
    model.load_state_dict(torch.load("hand_model.pth", map_location=device))
    model.eval()
    print("âœ… AI æ¨¡å‹åŠ è½½æˆåŠŸï¼")
except Exception as e:
    print(f"âŒ æ¨¡å‹æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ hand_model.pth æ˜¯å¦åœ¨å½“å‰æ–‡ä»¶å¤¹ä¸‹: {e}")
    exit()

# ==========================================
# 3. åˆå§‹åŒ– MediaPipe æ‰‹éƒ¨æ£€æµ‹
# ==========================================
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(
    static_image_mode=False,
    max_num_hands=1,
    min_detection_confidence=0.7,
    min_tracking_confidence=0.5
)
mp_draw = mp.solutions.drawing_utils

# ==========================================
# 4. å¼€å¯æ‘„åƒå¤´å¹¶å¼€å§‹å®æ—¶æ¨ç†
# ==========================================
cap = cv2.VideoCapture(0)
print("ğŸš€ ç³»ç»Ÿå·²å¯åŠ¨ï¼è¯·å¯¹ç€æ‘„åƒå¤´åšæ‰‹åŠ¿...")
print("æç¤ºï¼šæ¡æ‹³(çŸ³å¤´) -> äº®ç¯ | å¼ å¼€æ‰‹(å¸ƒ) -> ç­ç¯ | æŒ‰ 'q' é”®é€€å‡º")

last_cmd = ""  # ç”¨äºé˜²æ­¢é‡å¤å‘é€ç›¸åŒæŒ‡ä»¤ï¼Œå‡è½»ä¸²å£å‹åŠ›

while cap.isOpened():
    success, img = cap.read()
    if not success:
        break

    # é•œåƒå¤„ç†å¹¶è½¬æ¢é¢œè‰²
    img = cv2.flip(img, 1)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # æ‰‹éƒ¨å…³é”®ç‚¹è¯†åˆ«
    results = hands.process(img_rgb)

    current_action = "Waiting for hands..."

    if results.multi_hand_landmarks:
        for hand_landmarks in results.multi_hand_landmarks:
            # åœ¨ç”»é¢ä¸Šç”»å‡ºéª¨æ¶
            mp_draw.draw_landmarks(img, hand_landmarks, mp_hands.HAND_CONNECTIONS)

            # æå– 21 ä¸ªå…³é”®ç‚¹çš„ (x, y, z) åæ ‡ä½œä¸ºæ¨¡å‹è¾“å…¥
            coords = []
            for lm in hand_landmarks.landmark:
                coords.extend([lm.x, lm.y, lm.z])

            # æ¨¡å‹æ¨ç†
            input_tensor = torch.FloatTensor(coords).view(1, -1).to(device)
            with torch.no_grad():
                output = model(input_tensor)
                prediction = torch.argmax(output, dim=1).item()

            # --- æ ¸å¿ƒé€»è¾‘ï¼šæ‰‹åŠ¿æ§åˆ¶ç¡¬ä»¶ ---
            if prediction == 0:  # çŸ³å¤´
                current_action = "ROCK -> LED ON"
                if ser and last_cmd != "0":
                    ser.write(b'0')  # å‘ä¸²å£å‘é€å­—èŠ‚ 0
                    last_cmd = "0"
            elif prediction == 2:  # å¸ƒ
                current_action = "PAPER -> LED OFF"
                if ser and last_cmd != "2":
                    ser.write(b'2')  # å‘ä¸²å£å‘é€å­—èŠ‚ 2
                    last_cmd = "2"
            else:
                current_action = "SCISSORS -> No Action"

    # å°†è¯†åˆ«ç»“æœå®æ—¶æ˜¾ç¤ºåœ¨å›¾åƒçª—å£ä¸Š
    cv2.putText(img, current_action, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    cv2.imshow("TinyML Hand Control", img)

    # æŒ‰ Q é€€å‡º
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# é‡Šæ”¾èµ„æº
cap.release()
if ser:
    ser.close()
cv2.destroyAllWindows()